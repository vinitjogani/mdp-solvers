# Solving MDPs

The `environments.py` file describes the two MDPs that we work with: Chopsticks and Racecar, and includes some helper methods to make it easy to work with them.

The `solver.py` file includes 3 algorithms to solve those MDPs: Value Iteration, Policy Iteration and Q-learning. 

To run the code and generate the charts, simply open the `experiments.ipynb` and run all the cells. This includes several experiments on these algorithms to compute convergence, effect of parameters like exploration and discounting factor, and also includes some code to visualize the policies and value functions.

Self-link: https://github.com/vinitjogani/mdp-solvers 